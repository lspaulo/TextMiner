# -*- coding: utf-8 -*-
"""Data Integration, Ingestion & Quality.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Iije3clVejbBSUZ28TYOoDD-eg-r-NzD
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
!pip install nltk
import nltk
#sentence breaker
nltk.download('punkt')
#speech tagging
nltk.download('averaged_perceptron_tagger')
import nltk
from nltk.probability import FreqDist
import matplotlib.pyplot as plt

# Crawl the website and extract the text
def crawl_website():
  # Send a request to the website and get the HTML response
  response = requests.get('https://pt.wikipedia.org/wiki/Intelig%C3%AAncia_artificial')
  # Parse the HTML response using BeautifulSoup
  soup = BeautifulSoup(response.text, 'html.parser')
  # Find the main content div
  content = soup.find('div', {'id': 'mw-content-text'})
  # Extract the text from the content div
  text = content.get_text()
  # Return the extracted text
  return text

# Count the occurrences of the words "GPT-3" and "artificial intelligence"
def count_words(text):
  # Convert the text to lowercase
  text = text.lower()
  # Count the occurrences of "GPT-3"
  count_alg = text.count('algoritmo')
  # Count the occurrences of "artificial intelligence"
  count_rn = text.count('redes neurais')
  # Return the counts
  return count_alg, count_rn

# Save the data to a CSV file
def save_data(count_alg, count_rn):
  # Create a DataFrame with the data
  data = {'world': ['Algoritmo', 'Redes Neurais'], 'Ocurrences': [count_alg, count_rn]}
  df = pd.DataFrame(data)
  # Save the DataFrame to a CSV file
  df.to_csv('ocurrences.csv', index=False)

def visualize_data(count_alg, count_rn):
  # Create a bar chart with the data
  plt.bar(['Machine Learning', 'Redes Neurais'], [count_alg, count_rn])
  plt.xlabel('World')
  plt.ylabel('Ocurrences')
  plt.title('Number of Occurrences of Words in the Text')
  plt.show()

# Main function
def main():
  # Crawl the website
  text = crawl_website()
  # Count the words
  count_alg, count_rn = count_words(text)
  # Save the data
  save_data(count_alg, count_rn)
  visualize_data(count_alg, count_rn)
def save_data(count_alg, count_rn):
  # Create a dictionary to a pandas DataFrame
  data = {'world': ['Algoritmo', 'Redes Neurais'], 'Ocurrences': [count_alg, count_rn]}
  # Convert the dictionary to a pandas DataFrame
  df = pd.DataFrame.from_dict(data)
  # Save the DaraFrame to a CSV file
  df.to_csv('ocurrences.csv', index=False)
if __name__ == '__main__':
  main()

print(count_words(crawl_website()))